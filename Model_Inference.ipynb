{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3140abaf",
   "metadata": {
    "id": "3140abaf"
   },
   "source": [
    "### Change Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e9224f",
   "metadata": {
    "id": "12e9224f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cd \"C:/Users/Karpoh/Desktop/Code/DeepLearnAss2/Inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_fmVI-Ze0qfD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1682060783538,
     "user": {
      "displayName": "Jonathan 33",
      "userId": "13238689032685541467"
     },
     "user_tz": -480
    },
    "id": "_fmVI-Ze0qfD",
    "outputId": "eaa9505e-15cc-43b3-ec0a-7e3eadf76f20",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kxMtx4nQAS-7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20666,
     "status": "ok",
     "timestamp": 1682060804195,
     "user": {
      "displayName": "Jonathan 33",
      "userId": "13238689032685541467"
     },
     "user_tz": -480
    },
    "id": "kxMtx4nQAS-7",
    "outputId": "ab3b406b-ed54-4f3a-d660-40c0c849a5fd"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jj10NNwGCCCb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1046,
     "status": "ok",
     "timestamp": 1682060805237,
     "user": {
      "displayName": "Jonathan 33",
      "userId": "13238689032685541467"
     },
     "user_tz": -480
    },
    "id": "jj10NNwGCCCb",
    "outputId": "85f48d40-827f-45c6-9d3c-e69568075d32"
   },
   "outputs": [],
   "source": [
    "#cd /content/drive/MyDrive/UCCD3074_GroupAssignment/Final/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653b9040",
   "metadata": {
    "id": "653b9040"
   },
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2U4cVy9u17",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1682066017783,
     "user": {
      "displayName": "Jonathan 33",
      "userId": "13238689032685541467"
     },
     "user_tz": -480
    },
    "id": "8f2U4cVy9u17"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import glob as glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import albumentations as A\n",
    "import time\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.nn import functional as F\n",
    "from torch import topk\n",
    "from torch.nn.modules.module import register_module_forward_hook\n",
    "import torchvision.models as models\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import resnet18, ResNet18_Weights, ResNet50_Weights\n",
    "\n",
    "imgSize = 224\n",
    "\n",
    "#from model import build_model\n",
    "# Define computation device.\n",
    "device = 'cpu'\n",
    "# Class names.\n",
    "sign_names_df = pd.read_csv('signnames.csv')\n",
    "class_names = sign_names_df.SignName.tolist()\n",
    "\n",
    "# # DataFrame for ground truth.\n",
    "# gt_df = pd.read_csv(\n",
    "#     'Inference/Test.csv', \n",
    "#     delimiter=';'\n",
    "# )\n",
    "# gt_df = gt_df.set_index('Filename', drop=True)\n",
    "\n",
    "#Read different testing folder\n",
    "gt_df = pd.read_csv('../Test.csv')\n",
    "gt_df = gt_df.set_index('Path', drop=True)\n",
    "\n",
    "# Initialize model, switch to eval model, load trained weights.\n",
    "model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "#model = models.inception_v3(pretrained=True)\n",
    "#model = models.alexnet(pretrained=True)\n",
    "\n",
    "#Modify the fully connected layer\n",
    "num_features = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_features, 43)\n",
    "\n",
    "#num_features = model.classifier[6].in_features\n",
    "#model.fc = torch.nn.Linear(num_features, 43)\n",
    "model.load_state_dict(torch.load(\"../models/PreTrained_ResNet18_v3.6.pth\"))\n",
    "#model.load_state_dict(torch.load(\"models/PreTrained_Inception_v1.0.pth\"))\n",
    "#model.load_state_dict(torch.load(\"models/PreTrained_AlexNet_v1.0.pth\"))\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KWz5aFgY8gBz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1682066023716,
     "user": {
      "displayName": "Jonathan 33",
      "userId": "13238689032685541467"
     },
     "user_tz": -480
    },
    "id": "KWz5aFgY8gBz",
    "outputId": "ddebfcf1-dd3e-45b6-866b-3976ac8c525a"
   },
   "outputs": [],
   "source": [
    "# for name, _ in model.named_children():\n",
    "#   print(name)\n",
    "\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2xXRd7Wo8l9K",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1682066062279,
     "user": {
      "displayName": "Jonathan 33",
      "userId": "13238689032685541467"
     },
     "user_tz": -480
    },
    "id": "2xXRd7Wo8l9K",
    "outputId": "b2cacfce-ce97-4c96-c4b8-03b1ce241275"
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "\n",
    "# summary(model, (3,224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41f2802",
   "metadata": {
    "id": "e41f2802"
   },
   "source": [
    "### Define Function To Print HeatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2xLB3iJM9vxD",
   "metadata": {
    "id": "2xLB3iJM9vxD"
   },
   "outputs": [],
   "source": [
    "def returnCAM(feature_conv, weight_softmax, class_idx):\n",
    "    # Generate the class activation maps upsample to 256x256.\n",
    "    size_upsample = (256, 256)\n",
    "    bz, nc, h, w = feature_conv.shape\n",
    "    output_cam = []\n",
    "    for idx in class_idx:\n",
    "        #print(weight_softmax[idx].shape)\n",
    "        cam = weight_softmax[idx].dot(feature_conv.reshape((nc, h*w)))\n",
    "\n",
    "        #print('cam', cam)\n",
    "        #print('shape', feature_conv.shape)\n",
    "        cam = cam.reshape(h, w)\n",
    "        cam = cam - np.min(cam)\n",
    "        cam_img = cam / np.max(cam)\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "        output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "    return output_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ca91ef",
   "metadata": {
    "id": "a8ca91ef"
   },
   "outputs": [],
   "source": [
    "def apply_color_map(CAMs, width, height, orig_image):\n",
    "    for i, cam in enumerate(CAMs):\n",
    "        heatmap = cv2.applyColorMap(cv2.resize(cam,(width, height)), cv2.COLORMAP_JET)\n",
    "        result = heatmap * 0.5 + orig_image * 0.5\n",
    "        result = cv2.resize(result, (imgSize, imgSize))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bc3e97",
   "metadata": {
    "id": "d5bc3e97"
   },
   "outputs": [],
   "source": [
    "def visualize_and_save_map(result, orig_image, gt_idx=None, class_idx=None, save_name=None):\n",
    "    # Put class label text on the result.\n",
    "    if class_idx is not None:\n",
    "        cv2.putText(\n",
    "            result, \n",
    "            f\"Pred: {str(class_names[int(class_idx)])}\", (5, 20), \n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.55, (0, 255, 0), 2,\n",
    "            cv2.LINE_AA\n",
    "        )\n",
    "    if gt_idx is not None:\n",
    "        cv2.putText(\n",
    "            result, \n",
    "            f\"GT: {str(class_names[int(gt_idx)])}\", (5, 40), \n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.55, (0, 255, 0), 2,\n",
    "            cv2.LINE_AA\n",
    "        )\n",
    "    \n",
    "    ####################\n",
    "    # Resize the original image\n",
    "    orig_image = cv2.resize(orig_image, (imgSize, imgSize))\n",
    "\n",
    "    # Combine the result and original images side-by-side\n",
    "    img_concat = np.concatenate([result, orig_image], axis=1)\n",
    "\n",
    "    # Display the result using pyplot\n",
    "    plt.imshow(img_concat/255.)\n",
    "    plt.title('Result')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j7fdwbfryyNM",
   "metadata": {
    "id": "j7fdwbfryyNM"
   },
   "outputs": [],
   "source": [
    "#summary(model, (3,244,244))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rLntJuEK9xlz",
   "metadata": {
    "id": "rLntJuEK9xlz"
   },
   "outputs": [],
   "source": [
    "# Hook the feature extractor.\n",
    "# https://github.com/zhoubolei/CAM/blob/master/pytorch_CAM.py\n",
    "features_blobs = []\n",
    "def hook_feature(module, input, output):\n",
    "    features_blobs.append(output.data.cpu().numpy())\n",
    "\n",
    "#Resnet\n",
    "model.layer4.register_forward_hook(hook_feature) \n",
    "\n",
    "#Inception\n",
    "#model.AuxLogits.register_forward_hook(hook_feature) \n",
    "\n",
    "#AlexNet\n",
    "#model.features.register_forward_hook(hook_feature) \n",
    "\n",
    "# Get the softmax weight.\n",
    "params = list(model.parameters())\n",
    "weight_softmax = np.squeeze(params[-2].data.cpu().numpy())\n",
    "#print(weight_softmax.shape)\n",
    "#print(weight_softmax)\n",
    "# Define the transforms, resize => tensor => normalize.\n",
    "transform = A.Compose([\n",
    "    A.Resize(imgSize, imgSize),\n",
    "    A.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "    ToTensorV2(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c552d217",
   "metadata": {
    "id": "c552d217"
   },
   "source": [
    "## Inference and Print HeatMap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k4MQ5RYQuhFs",
   "metadata": {
    "id": "k4MQ5RYQuhFs"
   },
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38f3d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "# Reference: https://github.com/zhoubolei/CAM/blob/master/pytorch_CAM.py\n",
    "#################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c90c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XrkexzgFuh2-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 99074,
     "status": "ok",
     "timestamp": 1682060926553,
     "user": {
      "displayName": "Jonathan 33",
      "userId": "13238689032685541467"
     },
     "user_tz": -480
    },
    "id": "XrkexzgFuh2-",
    "outputId": "66ebbb47-eab8-4f95-cfcf-e9d1b2b28916",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "# Run for all the test images.\n",
    "#all_images = glob.glob('/content/drive/MyDrive/UCCD3074/TrafficSignRecognition/GTSRB/Final_Test/Images/*.ppm')\n",
    "## Images from different test folder\n",
    "all_images = glob.glob('../Test/*.png')\n",
    "\n",
    "correct_count = 0\n",
    "frame_count = 0 # To count total frames.\n",
    "total_fps = 0 # To get the final frames per second. \n",
    "for i, image_path in enumerate(all_images):\n",
    "    # Read the image.\n",
    "    image = cv2.imread(image_path)\n",
    "    orig_image = image.copy()\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    height, width, _ = orig_image.shape\n",
    "    # Apply the image transforms.\n",
    "    image_tensor = transform(image=image)['image']\n",
    "    # Add batch dimension.\n",
    "    image_tensor = image_tensor.unsqueeze(0)\n",
    "    # Forward pass through model.\n",
    "    start_time = time.time()\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # image_tensor = image_tensor.to(device)\n",
    "    # outputs = model(image_tensor) \n",
    "    \n",
    "    model = model.to(device)\n",
    "    outputs = model(image_tensor.to(device))\n",
    "    end_time = time.time()\n",
    "    # Get the softmax probabilities.\n",
    "    probs = F.softmax(outputs, dim=1).data.squeeze()\n",
    "    # Get the class indices of top k probabilities.\n",
    "    class_idx = topk(probs, 1)[1].int()\n",
    "    #print(class_idx)\n",
    "    # Get the ground truth.\n",
    "    image_name = image_path.split(os.path.sep)[-1]\n",
    "    ## Different Testing Folder\n",
    "    image_name = \"Test/\" + image_name\n",
    "    gt_idx = gt_df.loc[image_name].ClassId\n",
    "    # Check whether correct prediction or not.\n",
    "    if gt_idx == class_idx:\n",
    "        correct_count += 1\n",
    "\n",
    "    # Append to true_labels and pred_labels\n",
    "    true_labels.append(gt_idx)\n",
    "    pred_labels.append(class_idx)\n",
    "\n",
    "    # Generate class activation mapping for the top1 prediction.\n",
    "    CAMs = returnCAM(features_blobs[0], weight_softmax, class_idx)\n",
    "    # File name to save the resulting CAM image with.\n",
    "    save_name = f\"{image_path.split('/')[-1].split('.')[0]}\"\n",
    "    # Show and save the results.\n",
    "    result = apply_color_map(CAMs, width, height, orig_image)\n",
    "#     if(gt_idx == 23 and gt_idx != class_idx):\n",
    "#         visualize_and_save_map(result, orig_image, gt_idx, class_idx, save_name)\n",
    "    visualize_and_save_map(result, orig_image, gt_idx, class_idx, save_name)\n",
    "    if gt_idx != class_idx:\n",
    "        incorrect.append(gt_idx)\n",
    "    counter += 1\n",
    "    #print(f\"Image: {counter}\")\n",
    "    # Get the current fps.\n",
    "    #fps = 1 / (end_time - start_time)\n",
    "    # Add `fps` to `total_fps`.\n",
    "    #total_fps += fps\n",
    "    # Increment frame count.\n",
    "    #frame_count += 1\n",
    "print(f\"Total number of test images: {len(all_images)}\")\n",
    "print(f\"Total correct predictions: {correct_count}\")\n",
    "print(f\"Accuracy: {correct_count/len(all_images)*100:.3f}\")\n",
    "\n",
    "# calculate and print the average FPS\n",
    "#avg_fps = total_fps / frame_count\n",
    "#print(f\"Average FPS: {avg_fps:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a384f3",
   "metadata": {
    "id": "37a384f3"
   },
   "source": [
    "# Print Accuracy without HeatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28fe624",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2122,
     "status": "ok",
     "timestamp": 1682060942455,
     "user": {
      "displayName": "Jonathan 33",
      "userId": "13238689032685541467"
     },
     "user_tz": -480
    },
    "id": "f28fe624",
    "outputId": "4525a232-641a-4db1-c6d5-e239dcf1762b"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Run for all the test images.\n",
    "#all_images = glob.glob('/content/drive/MyDrive/UCCD3074/TrafficSignRecognition/GTSRB/Final_Test/Images/*.ppm')\n",
    "all_images = glob.glob('../Test/*.png')\n",
    "correct_count = 0\n",
    "total = 0 \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for i, image_path in enumerate(all_images):\n",
    "    # Read the image.\n",
    "    image = cv2.imread(image_path)\n",
    "    orig_image = image.copy()\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    height, width, _ = orig_image.shape\n",
    "    # Apply the image transforms.\n",
    "    image_tensor = transform(image=image)['image']\n",
    "    # Add batch dimension.\n",
    "    image_tensor = image_tensor.unsqueeze(0)\n",
    "   \n",
    "    model = model.to(device)\n",
    "    outputs = model(image_tensor.to(device))\n",
    "\n",
    "    # Get the softmax probabilities.\n",
    "    probs = F.softmax(outputs, dim=1).data.squeeze()\n",
    "    # Get the class indices of top k probabilities.\n",
    "    class_idx = topk(probs, 1)[1].int()\n",
    "    # Get the ground truth.\n",
    "    image_name = image_path.split(os.path.sep)[-1]\n",
    "    image_name = \"Test/\" + image_name\n",
    "    gt_idx = gt_df.loc[image_name].ClassId\n",
    "    # Check whether correct prediction or not.\n",
    "    if gt_idx == class_idx:\n",
    "        correct_count += 1\n",
    "    \n",
    "    if gt_idx != class_idx:\n",
    "        incorrect.append(gt_idx)\n",
    "    \n",
    "    total+=1\n",
    "\n",
    "print(\"Total correct : %d/%d \\nAccuracy: %f\" %(correct_count, total, correct_count/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ecd1d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create an empty dictionary to store counts of each number\n",
    "counts = {}\n",
    "\n",
    "# Loop through each number in the list and update the dictionary\n",
    "for num in incorrect:\n",
    "    if num in counts:\n",
    "        counts[num] += 1\n",
    "    else:\n",
    "        counts[num] = 1\n",
    "\n",
    "# Print the counts of each number in ascending order\n",
    "for num, count in sorted(counts.items()):\n",
    "    print(num, \":\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efc72f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1682061598638,
     "user": {
      "displayName": "Jonathan 33",
      "userId": "13238689032685541467"
     },
     "user_tz": -480
    },
    "id": "4efc72f1",
    "outputId": "3e65153d-fd1f-43ca-c24b-428225ea6a0d"
   },
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Convert pred_labels from list to tensor\n",
    "pred_labels_tensor = torch.tensor(pred_labels)\n",
    "true_labels_tensor = torch.tensor(true_labels)\n",
    "\n",
    "# Assuming true_labels is a tensor\n",
    "true_labels_cpu = true_labels_tensor.cpu()\n",
    "\n",
    "# Copy the predicted labels tensor to the CPU\n",
    "pred_labels_cpu = pred_labels_tensor.cpu()\n",
    "\n",
    "# Pass CPU tensors to classification_report function\n",
    "print(classification_report(true_labels_cpu, pred_labels_cpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Y7-PDWkhAeTx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 6398,
     "status": "ok",
     "timestamp": 1682067088669,
     "user": {
      "displayName": "Jonathan 33",
      "userId": "13238689032685541467"
     },
     "user_tz": -480
    },
    "id": "Y7-PDWkhAeTx",
    "outputId": "29f57f48-c6e2-4699-a502-ac5b16122d52"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics._plot.confusion_matrix import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming true_labels is a tensor\n",
    "true_labels_cpu = true_labels_tensor.cpu()\n",
    "\n",
    "# Copy the predicted labels tensor to the CPU\n",
    "pred_labels_cpu = pred_labels_tensor.cpu()\n",
    "\n",
    "# Define classes\n",
    "classes = np.unique(true_labels_cpu)\n",
    "classes = [str(c) for c in classes]\n",
    "\n",
    "# Get the confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels_cpu, pred_labels_cpu)\n",
    "\n",
    "# Calculate percentage of predicted for each class\n",
    "conf_matrix_percent = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix_percent, display_labels=classes)\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "cm_display.plot(values_format='.1f', cmap='Greens', ax=ax)\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xz7nVSnfhAbL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1796,
     "status": "ok",
     "timestamp": 1682063599906,
     "user": {
      "displayName": "Jonathan 33",
      "userId": "13238689032685541467"
     },
     "user_tz": -480
    },
    "id": "Xz7nVSnfhAbL",
    "outputId": "e58cd0fd-60d3-4040-c98e-83aaaeb0cb31"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Binarize the labels\n",
    "n_classes = 43\n",
    "true_labels_np = true_labels_cpu.numpy()\n",
    "true_labels_onehot = label_binarize(true_labels_np, classes=np.arange(n_classes))\n",
    "\n",
    "# Binarize the predicted labels\n",
    "pred_labels_onehot = label_binarize(pred_labels_cpu.numpy(), classes=np.arange(n_classes))\n",
    "\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "colours = []\n",
    "\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(true_labels_onehot[:, i], pred_labels_onehot[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    colour = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "    # Convert the RGB tuple to a hex string\n",
    "    colour_hex = '#{:02x}{:02x}{:02x}'.format(*colour)\n",
    "    colours.append(colour_hex)\n",
    "\n",
    "    \n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, color in zip(range(n_classes), colours):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2, label='ROC curve of class {0} (AUC = {1:0.2f})'\n",
    "                                               ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dGWbG9fLwqsD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 872
    },
    "executionInfo": {
     "elapsed": 969,
     "status": "ok",
     "timestamp": 1682063613837,
     "user": {
      "displayName": "Jonathan 33",
      "userId": "13238689032685541467"
     },
     "user_tz": -480
    },
    "id": "dGWbG9fLwqsD",
    "outputId": "130fb89a-8225-4b27-c39e-7992ec0139e2"
   },
   "outputs": [],
   "source": [
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(true_labels_onehot.ravel(), pred_labels_onehot.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at these points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "\n",
    "# Plot micro-average ROC curve\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"], label='micro-average ROC curve (AUC = {0:0.2f})'\n",
    "                                             ''.format(roc_auc[\"micro\"]), color='deeppink', linestyle=':', linewidth=4)\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"], label='macro-average ROC curve (AUC = {0:0.2f})'\n",
    "                                             ''.format(roc_auc[\"macro\"]), color='navy', linestyle=':', linewidth=4)\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve for Micro & Macro-average')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vP0I-aerx7qc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3244,
     "status": "ok",
     "timestamp": 1682063582948,
     "user": {
      "displayName": "Jonathan 33",
      "userId": "13238689032685541467"
     },
     "user_tz": -480
    },
    "id": "vP0I-aerx7qc",
    "outputId": "b0bc7004-cef4-443a-9529-d70877ea046e"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# Compute precision-recall curve and average precision score for each class\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "colours = []\n",
    "\n",
    "for i in range(n_classes):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(true_labels_onehot[:, i], pred_labels_onehot[:, i])\n",
    "    average_precision[i] = average_precision_score(true_labels_onehot[:, i], pred_labels_onehot[:, i])\n",
    "    colour = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "    # Convert the RGB tuple to a hex string\n",
    "    colour_hex = '#{:02x}{:02x}{:02x}'.format(*colour)\n",
    "    colours.append(colour_hex)\n",
    "\n",
    "# Plot precision-recall curve\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, color in zip(range(n_classes), colours):\n",
    "    plt.plot(recall[i], precision[i], color=color, lw=2, label='PR curve of class {0} (avg = {1:0.2f})'\n",
    "                                               ''.format(i, average_precision[i]))\n",
    "\n",
    "plt.xlim([0.0, 1.05])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "M7LVa-MhuKS-",
   "metadata": {
    "id": "M7LVa-MhuKS-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "c552d217",
    "OO8escy8vBZs"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
